{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_inception\n",
    "#coding:utf-8\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='5,6'\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "from scipy import misc\n",
    "# 创建图和会话\n",
    "graph=tf.Graph()\n",
    "sess=tf.InteractiveSession(graph=graph)\n",
    "\n",
    "# tensorflow_inception_graph.pb文件中，既存储了inception的网络结构，也存储了对应的数据\n",
    "model_fn='tensorflow_inception_graph.pb'\n",
    "with tf.gfile.FastGFile(model_fn,'rb') as f:\n",
    "    graph_def=tf.GraphDef()\n",
    "    graph_def.ParseFromString(f.read())\n",
    "# 定义t_input为输入的图像\n",
    "t_input=tf.placeholder(np.float32,name='input')\n",
    "imagenet_mean=117.0\n",
    "t_preprocessed=tf.expand_dims(t_input-imagenet_mean,0) #增加一个维度\n",
    "tf.import_graph_def(graph_def,{'input':t_preprocessed})\n",
    "def savearray(img_array,img_name):\n",
    "    scipy.misc.toimage(img_array).save(img_name)\n",
    "    print('img saved:%s'%img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers 59\n",
      "shape of mixed4d_3x3_bottleneck_pre_relu:(?, ?, ?, 144)\n"
     ]
    }
   ],
   "source": [
    "# test 输出模型信息\n",
    "# 找到所有的卷积层\n",
    "layers=[op.name for op in graph.get_operations() if op.type=='Conv2D'and 'import/'in op.name]\n",
    "print('Number of layers',len(layers))\n",
    "name='mixed4d_3x3_bottleneck_pre_relu'\n",
    "print('shape of %s:%s'%(name,str(graph.get_tensor_by_name('import/'+name+':0').get_shape())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score(mean)=-19.670834\n",
      "score(mean)=-31.371943\n",
      "score(mean)=17.438494\n",
      "score(mean)=93.795532\n",
      "score(mean)=153.782257\n",
      "score(mean)=213.928558\n",
      "score(mean)=275.163025\n",
      "score(mean)=322.561890\n",
      "score(mean)=364.350403\n",
      "score(mean)=410.050476\n",
      "score(mean)=448.293030\n",
      "score(mean)=492.061615\n",
      "score(mean)=530.295105\n",
      "score(mean)=556.363159\n",
      "score(mean)=593.981689\n",
      "score(mean)=617.850037\n",
      "score(mean)=651.571838\n",
      "score(mean)=674.279175\n",
      "score(mean)=697.457703\n",
      "score(mean)=721.733643\n",
      "img saved:naive.jpg\n"
     ]
    }
   ],
   "source": [
    "# gen_naive\n",
    "def render_naive(t_obj,img0,iter_n=20,step=1.0):\n",
    "    # t_score 是优化目标，它是t_obj的平均值\n",
    "    t_score=tf.reduce_mean(t_obj)\n",
    "    # 计算t_score对t_input的梯度\n",
    "    t_grad=tf.gradients(t_score,t_input)[0]\n",
    "    # 创建新图\n",
    "    img=img0.copy()\n",
    "    for i in range(iter_n):\n",
    "        # 在sess中计算梯度，以及当前的score\n",
    "        g,score=sess.run([t_grad,t_score],{t_input:img})\n",
    "        # 对img应用梯度，step可以看作学习率\n",
    "        g/=g.std()+1e-8\n",
    "        img+=g*step\n",
    "        print('score(mean)=%f'%score)\n",
    "    savearray(img,'naive.jpg')\n",
    "name='mixed4d_3x3_bottleneck_pre_relu'\n",
    "channel=139\n",
    "layer_output=graph.get_tensor_by_name('import/%s:0'%name)\n",
    "# 定义原始的图像噪声\n",
    "img_noise=np.random.uniform(size=(224,224,3))+100.0\n",
    "# 调用render_naive函数渲染\n",
    "render_naive(layer_output[:,:,:,channel],img_noise,iter_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . img saved:multiscale.jpg\n"
     ]
    }
   ],
   "source": [
    "# gen_multiscale\n",
    "def calc_grad_tiled(img, t_grad, tile_size=512):\n",
    "    # 每次只对tile_size×tile_size大小的图像计算梯度，避免内存问题\n",
    "    sz = tile_size\n",
    "    h, w = img.shape[:2]\n",
    "    # img_shift：先在行上做整体移动，再在列上做整体移动\n",
    "    # 防止在tile的边缘产生边缘效应\n",
    "    sx, sy = np.random.randint(sz, size=2)\n",
    "    img_shift = np.roll(np.roll(img, sx, 1), sy, 0)\n",
    "    grad = np.zeros_like(img)\n",
    "    # y, x是开始位置的像素\n",
    "    for y in range(0, max(h - sz // 2, sz), sz):\n",
    "        for x in range(0, max(w - sz // 2, sz), sz):\n",
    "            # 每次对sub计算梯度。sub的大小是tile_size×tile_size\n",
    "            sub = img_shift[y:y + sz, x:x + sz]\n",
    "            g = sess.run(t_grad, {t_input: sub})\n",
    "            grad[y:y + sz, x:x + sz] = g\n",
    "    # 使用np.roll移动回去\n",
    "    return np.roll(np.roll(grad, -sx, 1), -sy, 0)\n",
    "def resize_ratio(img,ratio):\n",
    "    min=img.min()\n",
    "    max=img.max()\n",
    "    img=((img-min)/(max-min))*255\n",
    "    img=np.float32(scipy.misc.imresize(img,ratio))\n",
    "    img=(img/255)*(max-min)+min\n",
    "    return img\n",
    "def render_multiscale(t_obj, img0, iter_n=10, step=1.0, octave_n=3, octave_scale=1.4):\n",
    "    # 同样定义目标和梯度\n",
    "    t_score = tf.reduce_mean(t_obj)\n",
    "    t_grad = tf.gradients(t_score, t_input)[0]\n",
    "\n",
    "    img = img0.copy()\n",
    "    for octave in range(octave_n):\n",
    "        if octave > 0:\n",
    "            # 每次将将图片放大octave_scale倍\n",
    "            # 共放大octave_n - 1 次\n",
    "            img = resize_ratio(img, octave_scale)\n",
    "        for i in range(iter_n):\n",
    "            # 调用calc_grad_tiled计算任意大小图像的梯度\n",
    "            g = calc_grad_tiled(img, t_grad)\n",
    "            g /= g.std() + 1e-8\n",
    "            img += g * step\n",
    "            print('.', end=' ')\n",
    "    savearray(img, 'multiscale.jpg')\n",
    "\n",
    "if __name__=='__main__':\n",
    "    name='mixed4d_3x3_bottleneck_pre_relu'\n",
    "    channel=139\n",
    "    img_noise=np.random.uniform(size=(224,224,3))+100.0\n",
    "    layer_output=graph.get_tensor_by_name(\"import/%s:0\"%name)\n",
    "    render_multiscale(layer_output[:,:,:,channel],img_noise,iter_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . img saved:lapnorm.jpg\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "k=np.float32([1,4,6,4,1])\n",
    "k=np.outer(k,k)\n",
    "k5x5=k[:,:,None,None]/k.sum()*np.eye(3,dtype=np.float32)\n",
    "# 将图像分为高频和低频\n",
    "def lap_split(img):\n",
    "    #这个函数将图像分为低频和高频成分\n",
    "    with tf.name_scope('split'):\n",
    "        # 做一次卷积相当于一次平滑，因此lo为低频成分\n",
    "        lo=tf.nn.conv2d(img,k5x5,[1,2,2,1],'SAME')\n",
    "        # 低频成分缩放到原始图像一样大小得到lo2，再用原始图像img减去lo2，就得到高频成分hi\n",
    "        lo2=tf.nn.conv2d_transpose(lo,k5x5*4,tf.shape(img),[1,2,2,1])\n",
    "        hi=img-lo2\n",
    "    return lo,hi\n",
    "\n",
    "# 将图像img分成n层拉普拉斯金字塔\n",
    "def lap_split_n(img,n):\n",
    "    levels=[]\n",
    "    for i in range(n):\n",
    "        # 调用lap_split将图像分为低频和高频，高频成分保存到levels中，低频成分继续分解\n",
    "        img,hi=lap_split(img)\n",
    "        levels.append(hi)\n",
    "    levels.append(img)\n",
    "    # a[::-1],就是将a翻转过来的意思,从最后一个到第一个开始\n",
    "    return levels[::-1]\n",
    "\n",
    "# 将拉普拉斯金字塔还原到原始图像\n",
    "def lap_merge(levels):\n",
    "    img=levels[0]\n",
    "    for hi in levels[1:]:\n",
    "        with tf.name_scope('merge'):\n",
    "            img=tf.nn.conv2d_transpose(img,k5x5*4,tf.shape(hi),[1,2,2,1])+hi\n",
    "    return img\n",
    "\n",
    "#对img进行标准化\n",
    "def normalize_std(img,eps=1e-10):\n",
    "    with tf.name_scope('normalize'):\n",
    "        std=tf.sqrt(tf.reduce_mean(tf.square(img)))\n",
    "        return img/tf.maximum(std,eps)\n",
    "\n",
    "# 将拉普拉斯金字塔标准化\n",
    "def lap_normalize(img,scale_n=4):\n",
    "    img=tf.expand_dims(img,0)\n",
    "    tlevels=lap_split_n(img,scale_n)\n",
    "    # 每次都做一次normalized_std\n",
    "    tlevels=list(map(normalize_std,tlevels))\n",
    "    out=lap_merge(tlevels)\n",
    "    return out[0,:,:,:]\n",
    "\n",
    "\n",
    "\n",
    "def tffunc(*argtypes):\n",
    "    placeholders=list(map(tf.placeholder,argtypes))\n",
    "    def wrap(f):\n",
    "        out=f(*placeholders)\n",
    "        def wrapper(*args,**kw):\n",
    "            return out.eval(dict(zip(placeholders,args)),session=kw.get('session'))\n",
    "        return wrapper\n",
    "    return wrap\n",
    "def render_lapnorm(t_obj,img0,iter_n=10,step=1.0,octave_n=3,octave_scale=1.4,lap_n=4):\n",
    "    # 定义目标和梯度\n",
    "    t_score=tf.reduce_mean(t_obj)\n",
    "    t_grad=tf.gradients(t_score,t_input)[0]\n",
    "    # 将lap_normalize转换为正常函数\n",
    "    lap_norm_func=tffunc(np.float32)(partial(lap_normalize,scale_n=lap_n))\n",
    "    img=img0.copy()\n",
    "    for octave in range(octave_n):\n",
    "        if octave>0:\n",
    "            img=resize_ratio(img,octave_scale)\n",
    "        for i in range(iter_n):\n",
    "            g=calc_grad_tiled(img,t_grad)\n",
    "            # 唯一区别在于使用lap_norm_func将g标准化\n",
    "            g=lap_norm_func(g)\n",
    "            img+=g*step\n",
    "            print('.',end=' ')\n",
    "    savearray(img,'lapnorm.jpg')\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    name='mixed4d_3x3_bottleneck_pre_relu'\n",
    "    channel=140\n",
    "    img_noise=np.random.uniform(size=(224,224,3))+100.0\n",
    "    layer_output=graph.get_tensor_by_name('import/%s:0'%name)\n",
    "    render_lapnorm(layer_output[:,:,:,channel],img_noise,iter_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . img saved:deepdream.jpg\n"
     ]
    }
   ],
   "source": [
    "import PIL.Image\n",
    "def resize(img,hw):\n",
    "    min=img.min()\n",
    "    max=img.max()\n",
    "    img=(img-min)/(max-min)*255\n",
    "    img=np.float32(scipy.misc.imresize(img,hw))\n",
    "    img=img/255*(max-min)+min\n",
    "    return img\n",
    "def render_deepdream(t_obj,img0,iter_n=10,step=1.5,octave_n=4,octave_scale=1.4):\n",
    "    t_score=tf.reduce_mean(t_obj)\n",
    "    t_grad=tf.gradients(t_score,t_input)[0]\n",
    "    img=img0\n",
    "    # 同样将图像进行金字塔分解，此时提取高频，低频的方法比较简单，直接缩放就可以\n",
    "    octaves=[]\n",
    "    for i in range(octave_n-1):\n",
    "        hw=img.shape[:2]\n",
    "        lo=resize(img,np.int32(np.float32(hw)/octave_scale))\n",
    "        hi=img-resize(lo,hw)\n",
    "        img=lo\n",
    "        octaves.append(hi)\n",
    "    # 先生成低频的图像，再依次放大加上高频\n",
    "    for octave in range(octave_n):\n",
    "        if octave>0:\n",
    "            hi=octaves[-octave]\n",
    "            img=resize(img,hi.shape[:2])+hi\n",
    "        for i in range(iter_n):\n",
    "            g=calc_grad_tiled(img,t_grad)\n",
    "            img+=g*(step/(np.abs(g).mean()+1e-7))\n",
    "            print('.',end=' ')\n",
    "    img=img.clip(0,255)\n",
    "    savearray(img,'deepdream.jpg')\n",
    "\n",
    "if __name__=='__main__':\n",
    "    img0=PIL.Image.open('test.jpg')\n",
    "    img0=np.float32(img0)\n",
    "    name='mixed4d_3x3_bottleneck_pre_relu'\n",
    "    channel=135\n",
    "    layer_output=graph.get_tensor_by_name('import/%s:0'%name)\n",
    "    render_deepdream(layer_output[:,:,:,channel],img0,iter_n=150)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
